{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4aeae9a",
   "metadata": {
    "id": "b4aeae9a",
    "outputId": "b219016c-f5ee-433f-9beb-40897ef4b3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.idea', 'architecture-design', 'docker', 'drive-download-20211215T213754Z-001.zip', 'drive-download-20211221T190522Z-001.zip', 'evaluated-data', 'models', 'notebooks', 'README.md', 'scripts', 'simulated-data-raw', 'spark-warehouse', 'transformed-data', 'venv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\spark\\\\spark-3.1.2-bin-hadoop2.7\\\\spark-3.1.2-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "print(os.listdir())\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9270e698-c423-4523-b93f-a691e4a220fa",
   "metadata": {
    "id": "9270e698-c423-4523-b93f-a691e4a220fa"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b20177",
   "metadata": {
    "id": "97b20177"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Spark').master(\"local[*]\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e0b993",
   "metadata": {
    "id": "d9e0b993",
    "outputId": "336ca3a1-6e3d-451d-e1f7-ab863200a551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', '.idea', 'architecture-design', 'docker', 'drive-download-20211215T213754Z-001.zip', 'drive-download-20211221T190522Z-001.zip', 'evaluated-data', 'models', 'notebooks', 'README.md', 'scripts', 'simulated-data-raw', 'spark-warehouse', 'transformed-data', 'venv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())\n",
    "data = spark.read.parquet(\"transformed-data/training/training_set.parquet\", engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54175762",
   "metadata": {
    "id": "54175762",
    "outputId": "a52ec999-f5b1-4565-930e-f62f460b10e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: long (nullable = true)\n",
      " |-- TRANSACTION_ID: long (nullable = true)\n",
      " |-- TX_DATETIME: timestamp (nullable = true)\n",
      " |-- CUSTOMER_ID: long (nullable = true)\n",
      " |-- TERMINAL_ID: long (nullable = true)\n",
      " |-- TX_AMOUNT: double (nullable = true)\n",
      " |-- TX_TIME_SECONDS: long (nullable = true)\n",
      " |-- TX_TIME_DAYS: long (nullable = true)\n",
      " |-- TX_FRAUD: long (nullable = true)\n",
      " |-- TX_FRAUD_SCENARIO: long (nullable = true)\n",
      " |-- TX_DURING_NIGHT: integer (nullable = true)\n",
      " |-- TX_DURING_WEEKEND: integer (nullable = true)\n",
      " |-- CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW: double (nullable = true)\n",
      " |-- CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW: double (nullable = true)\n",
      " |-- CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW: double (nullable = true)\n",
      " |-- CUSTOMER_ID_NB_TX_1DAY_WINDOW: long (nullable = true)\n",
      " |-- CUSTOMER_ID_NB_TX_7DAY_WINDOW: long (nullable = true)\n",
      " |-- CUSTOMER_ID_NB_TX_30DAY_WINDOW: long (nullable = true)\n",
      " |-- CUSTOMER_ID_TERMINAL_ID_NB_TX_1DAY_WINDOW: long (nullable = true)\n",
      " |-- CUSTOMER_ID_TERMINAL_ID_NB_TX_7DAY_WINDOW: long (nullable = true)\n",
      " |-- CUSTOMER_ID_TERMINAL_ID_NB_TX_30DAY_WINDOW: long (nullable = true)\n",
      " |-- CUSTOMER_ID_MAX_AMOUNT_1DAY_WINDOW: double (nullable = true)\n",
      " |-- CUSTOMER_ID_MAX_AMOUNT_7DAY_WINDOW: double (nullable = true)\n",
      " |-- CUSTOMER_ID_MAX_AMOUNT_30DAY_WINDOW: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f480788",
   "metadata": {
    "id": "6f480788"
   },
   "outputs": [],
   "source": [
    "features = ['TX_AMOUNT', 'TX_DURING_NIGHT', 'TX_DURING_WEEKEND', 'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW',\n",
    "           'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW',\n",
    "           'CUSTOMER_ID_NB_TX_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
    "           'CUSTOMER_ID_TERMINAL_ID_NB_TX_1DAY_WINDOW', 'CUSTOMER_ID_TERMINAL_ID_NB_TX_7DAY_WINDOW', 'CUSTOMER_ID_TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
    "           'CUSTOMER_ID_MAX_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_MAX_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_MAX_AMOUNT_30DAY_WINDOW']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14c0a9-d1c0-4a6e-bc07-898d06bda14a",
   "metadata": {
    "id": "3d14c0a9-d1c0-4a6e-bc07-898d06bda14a"
   },
   "source": [
    "## Random Forest Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec990b38-5689-450e-96ba-96ec824cf51f",
   "metadata": {
    "id": "ec990b38-5689-450e-96ba-96ec824cf51f"
   },
   "outputs": [],
   "source": [
    "# # Index labels, adding metadata to the label column.\n",
    "# # Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"TX_FRAUD\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "\n",
    "featureIndexer = VectorAssembler(inputCols=features, outputCol=\"indexedFeatures\")\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                              labels=labelIndexer.labels)\n",
    "pipeline = Pipeline(stages=[featureIndexer, labelIndexer, rf, labelConverter])\n",
    "\n",
    "evaluator_pr = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [5, 10, 15, 20])\n",
    "    .build())\n",
    "\n",
    "\n",
    "crossval_roc = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_roc,\n",
    "    numFolds=5)\n",
    "\n",
    "model = crossval_roc.fit(data)\n",
    "model.write().overwrite().save('models/cv-random-forest-roc')\n",
    "\n",
    "crossval_pr = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_pr,\n",
    "    numFolds=5)\n",
    "\n",
    "model = crossval_pr.fit(data)\n",
    "model.write().overwrite().save('models/cv-random-forest-pr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade29116-4075-4962-a0b3-12bc22f8e9e0",
   "metadata": {
    "id": "ade29116-4075-4962-a0b3-12bc22f8e9e0"
   },
   "source": [
    "## Binomial logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c70e321d-19e6-4288-9128-5f3dd7c582c3",
   "metadata": {
    "id": "c70e321d-19e6-4288-9128-5f3dd7c582c3"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"TX_FRAUD\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "\n",
    "featureIndexer = VectorAssembler(inputCols=features, outputCol=\"indexedFeatures\")\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                              labels=labelIndexer.labels)\n",
    "pipeline = Pipeline(stages=[featureIndexer, labelIndexer, lr, labelConverter])\n",
    "\n",
    "evaluator_pr = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.01, 0.1])\n",
    "    .addGrid(lr.elasticNetParam, [0.3, 0.8, 1.0])\n",
    "    .addGrid(lr.maxIter, [5, 10])\n",
    "    .build())\n",
    "\n",
    "crossval_roc = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_roc,\n",
    "    numFolds=5)\n",
    "\n",
    "model = crossval_roc.fit(data)\n",
    "model.write().overwrite().save('models/cv-logistic-regression-roc')\n",
    "\n",
    "crossval_pr = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_pr,\n",
    "    numFolds=5)\n",
    "\n",
    "model = crossval_pr.fit(data)\n",
    "model.write().overwrite().save('models/cv-logistic-regression-pr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70339e-6c6f-4701-98a2-9139ff1ac708",
   "metadata": {},
   "source": [
    "## Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8a0ee4-db30-4461-ad31-543a3de48fb9",
   "metadata": {
    "id": "5a8a0ee4-db30-4461-ad31-543a3de48fb9",
    "outputId": "4715aff5-9304-484f-cc5c-5ad7344c46df"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# # Index labels, adding metadata to the label column.\n",
    "# # Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"TX_FRAUD\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "\n",
    "featureIndexer = VectorAssembler(inputCols=features, outputCol=\"indexedFeatures\")\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                              labels=labelIndexer.labels)\n",
    "pipeline = Pipeline(stages=[featureIndexer, labelIndexer, gbt, labelConverter])\n",
    "\n",
    "evaluator_pr = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "    .addGrid(gbt.maxIter, [5, 10])\n",
    "    .build())\n",
    "\n",
    "\n",
    "crossval_roc = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_roc,\n",
    "    numFolds=5)\n",
    "\n",
    "model = crossval_roc.fit(data)\n",
    "model.write().overwrite().save('models/cv-gbt-roc')\n",
    "\n",
    "crossval_pr = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_pr,\n",
    "    numFolds=5)\n",
    "\n",
    "model = crossval_pr.fit(data)\n",
    "model.write().overwrite().save('models/cv-gbt-pr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487998c8-0ddd-4110-8f4a-e6433ffa2279",
   "metadata": {
    "id": "cf1b82c1-40f2-4cb3-af36-64f10e7f93a7"
   },
   "source": [
    "## Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d89d5bfd-25f4-4d29-b1c5-8a6aeb7df226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "# # Index labels, adding metadata to the label column.\n",
    "# # Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"TX_FRAUD\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "\n",
    "featureIndexer = VectorAssembler(inputCols=features, outputCol=\"indexedFeatures\")\n",
    "\n",
    "svm = LinearSVC(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                              labels=labelIndexer.labels)\n",
    "pipeline = Pipeline(stages=[featureIndexer, labelIndexer, svm, labelConverter])\n",
    "\n",
    "evaluator_pr = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "    .addGrid(svm.maxIter, [5, 10])\n",
    "    .addGrid(svm.regParam, [0.01, 0.1])\n",
    "    .build())\n",
    "\n",
    "\n",
    "crossval_roc = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_roc,\n",
    "    numFolds=5)\n",
    "\n",
    "model = crossval_roc.fit(data)\n",
    "model.write().overwrite().save('models/cv-svm-roc')\n",
    "\n",
    "crossval_pr = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_pr,\n",
    "    numFolds=5)\n",
    "\n",
    "model = crossval_pr.fit(data)\n",
    "model.write().overwrite().save('models/cv-svm-pr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac50c21-1366-40fd-93c2-0d088e39836f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pyspark-ml.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
